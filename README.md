# smashggwebscrape

EDIT: As of 10/10/2021 changes to the website's source code have caused errors with the scraper

A program that scrapes a profile's Super Smash Bros results from their smashgg account.

Requirements to Run
pandas, seaborn, BeautifulSoup, their depedancies, and an internet connection

Summary
My goal was to take information from my smashgg account to create a graphical representation of my competitive gaming career. I built a webscraper that goes through a smashgg account's results pages and scrapes what it finds. The account defaults to mine but it will work with any account, so long as you change the variable in the program to that which appears behind the name of the account on the account's smashgg profile page. My program continutes to collect results pages until it comes across an empty page. The resulting pages are mined for specific important fields, and the information is transformed and presented in 6 different graphs. The first is a comparison of a player's results in online versus offline tournaments. The information I needed seemed to be represented as a json file, but because it was nearly impossible for me to determine where the file ended (and it had a lot of junk data) I instead parsed larger strings for keywords that were specific fields I needed.

The results are graphed in chronological order, showing the percentage of competition they outplaced. I chose this statistic over placement because winning a 13 person event is not as impressive as second at one with 130. While this representation isn't perfect, it gives a rough approximation of results over time. The next graph is events entered and is quite straightforward, being represented as a bar chart. One struggle I had with this is some tournament organizers give their events quite unorthodox names, and I would have to write a complicated regex to sort out some that weren\t immediately identifiable as the kind of events I was mainly looking for. In addition, some players might play other games entirely, and these results shouldn't be counted. Instead, I created an 'Other' event these events fell under. Next graph is events by state. I didn't include online events because the point of the graph was to demonstrate how much a player has traveled. The fourth graph is placement with respect to proportion. This shows how well a player is at keeping up with larger events. For amateurs like me, this graph isn't very exciting because I don't have many large events, and zero I did significantly well at, but it is more informing for better players. I didn't want to exclude any events, so the scale is less than desireable for looking only at smaller scale events. Next is an attempt to break down tournaments into several different class based on attendees, with Supermajor being 500+ attendees while Smashfests are under 12. Placments for each kind of event is graphed over time. Again, the scale of larger events makes it more difficult to absorb the information being conveyed, but if you look closely you can see my performance at "locals" has improved steadily. Lastly, I have a graph representing players' most common teammates for doubles. I included two pictures, one of my results and one of a top professional player to give you an idea of what these graphs look like.


Shortcomings and Possible Improvements
My first issue was how to get the fields I needed from the beautifulsoup object, which contained the HTML. My stradegies involved trying to gather the information back into a json file and writing my own grammar to create a data structure with the data I needed, but these failed because I could not find where the json file began and ended and there were too many unique cases for my own grammar to work. Another solution I discovered after was using a regex, and while this might be the best tool for the job, I am not currently comfortable enough with it to use it in this project. Instead, I created a list of my desired fields and searched for them in large strings that were in the HTML tags. This process taught me a lot about tackling large scale, difficult problems and the BeautifulSoup library. Next was graphing the data, which required me to remember and learn a ton of new tools in seaborn, pandas, and matplotlib. Because of the difference of sizes and prestige to each tournament, it was difficult to find a numerical way to rank them. I didn't want to ignore certain outlier results, but including them in the graph scale made it harder to intrepret the data. If I were to improve this project, I would include more graphs that would show zoomed in versions of previous graphs that were more difficult to understand. The information I got was just from the results page, but I also figured out I could use the urls found in the results page to go to the results page of each specific tournament and find a ton more data. I didn't want to do this with this project because I felt the amount of data was unnecessary and it would involving scraping hundreds of web pages which would drastically increase runtime. This might be a cool addition in the future if I can come up with creative ways to display the new information. Lastly, the color scheme isn't perfect, and while I personally love the yellow/black/rainbow color scheme, I think adapting the color of some parts of the graph would make it more appealing to a wider audience.
